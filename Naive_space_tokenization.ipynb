{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SRINIDHISAGI/NLP1/blob/main/Naive_space_tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "wdj9RMfoGPC2"
      },
      "cell_type": "markdown",
      "source": [
        "Colab is making it easier than ever to integrate powerful Generative AI capabilities into your projects. We are launching public preview for a simple and intuitive Python library (google.colab.ai) to access state-of-the-art language models directly within Pro and Pro+ subscriber Colab environments.  This means subscribers can spend less time on configuration and set up and more time bringing their ideas to life. With just a few lines of code, you can now perform a variety of tasks:\n",
        "- Generate text\n",
        "- Translate languages\n",
        "- Write creative content\n",
        "- Categorize text\n",
        "\n",
        "Happy Coding!\n",
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/Getting_started_with_google_colab_ai.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import re\n",
        "paragraph = \"The students didn’t finish their work on time. However, they promised to submit it tomorrow! Let’s hope they keep their word.\"\n",
        "\n",
        "naive_tokens = paragraph.split()\n",
        "\n",
        "\n",
        "corrected_tokens = re.findall(r\"\\w+|’\\w+|n't|[.,!?]\", paragraph)\n",
        "\n",
        "# Print results\n",
        "print(\"Naïve Tokenization:\")\n",
        "print(naive_tokens)\n",
        "print(\"\\nCorrected Tokenization:\")\n",
        "print(corrected_tokens)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "PIcY-aH5pAfH",
        "outputId": "37477145-3686-4690-b333-b755abbf3df5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naïve Tokenization:\n",
            "['The', 'students', 'didn’t', 'finish', 'their', 'work', 'on', 'time.', 'However,', 'they', 'promised', 'to', 'submit', 'it', 'tomorrow!', 'Let’s', 'hope', 'they', 'keep', 'their', 'word.']\n",
            "\n",
            "Corrected Tokenization:\n",
            "['The', 'students', 'didn', '’t', 'finish', 'their', 'work', 'on', 'time', '.', 'However', ',', 'they', 'promised', 'to', 'submit', 'it', 'tomorrow', '!', 'Let', '’s', 'hope', 'they', 'keep', 'their', 'word', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Sample paragraph\n",
        "paragraph = \"The students didn’t finish their work on time. However, they promised to submit it tomorrow! Let’s hope they keep their word.\"\n",
        "\n",
        "naive_tokens = paragraph.split()\n",
        "\n",
        "corrected_tokens = re.findall(r\"\\w+|’\\w+|n't|[.,!?]\", paragraph)\n",
        "\n",
        "print(\"Naïve Tokenization:\")\n",
        "print(naive_tokens)\n",
        "\n",
        "print(\"\\nCorrected Tokenization:\")\n",
        "print(corrected_tokens)\n",
        "\n",
        "print(\"\\nDifferences:\")\n",
        "for n, c in zip(naive_tokens, corrected_tokens):\n",
        "    if n != c:\n",
        "        print(f\"Naïve: {n:<10}  →  Corrected: {c}\")\n",
        "\n",
        "# If lengths differ (extra tokens in corrected version)\n",
        "if len(corrected_tokens) > len(naive_tokens):\n",
        "    extra = corrected_tokens[len(naive_tokens):]\n",
        "    print(\"\\nExtra tokens in corrected version:\", extra)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "sf0iunuypDzW",
        "outputId": "becc7ffc-123c-4a57-dde2-0dcbf3a5770a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naïve Tokenization:\n",
            "['The', 'students', 'didn’t', 'finish', 'their', 'work', 'on', 'time.', 'However,', 'they', 'promised', 'to', 'submit', 'it', 'tomorrow!', 'Let’s', 'hope', 'they', 'keep', 'their', 'word.']\n",
            "\n",
            "Corrected Tokenization:\n",
            "['The', 'students', 'didn', '’t', 'finish', 'their', 'work', 'on', 'time', '.', 'However', ',', 'they', 'promised', 'to', 'submit', 'it', 'tomorrow', '!', 'Let', '’s', 'hope', 'they', 'keep', 'their', 'word', '.']\n",
            "\n",
            "Differences:\n",
            "Naïve: didn’t      →  Corrected: didn\n",
            "Naïve: finish      →  Corrected: ’t\n",
            "Naïve: their       →  Corrected: finish\n",
            "Naïve: work        →  Corrected: their\n",
            "Naïve: on          →  Corrected: work\n",
            "Naïve: time.       →  Corrected: on\n",
            "Naïve: However,    →  Corrected: time\n",
            "Naïve: they        →  Corrected: .\n",
            "Naïve: promised    →  Corrected: However\n",
            "Naïve: to          →  Corrected: ,\n",
            "Naïve: submit      →  Corrected: they\n",
            "Naïve: it          →  Corrected: promised\n",
            "Naïve: tomorrow!   →  Corrected: to\n",
            "Naïve: Let’s       →  Corrected: submit\n",
            "Naïve: hope        →  Corrected: it\n",
            "Naïve: they        →  Corrected: tomorrow\n",
            "Naïve: keep        →  Corrected: !\n",
            "Naïve: their       →  Corrected: Let\n",
            "Naïve: word.       →  Corrected: ’s\n",
            "\n",
            "Extra tokens in corrected version: ['hope', 'they', 'keep', 'their', 'word', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Q3: Detect Multiword Expressions (MWEs) in a paragraph\n",
        "\n",
        "# Sample paragraph\n",
        "paragraph = \"John lives in New York City. By and large, he enjoys it there, \\\n",
        "but sometimes he feels like he might kick the bucket from stress.\"\n",
        "\n",
        "# List of MWEs\n",
        "mwe_list = [\n",
        "    \"New York City\",\n",
        "    \"kick the bucket\",\n",
        "    \"by and large\"\n",
        "]\n",
        "\n",
        "# Normalize paragraph (lowercase for easy matching)\n",
        "lower_text = paragraph.lower()\n",
        "\n",
        "# Detect MWEs\n",
        "detected = [mwe for mwe in mwe_list if mwe.lower() in lower_text]\n",
        "\n",
        "# Print results\n",
        "print(\"Paragraph:\")\n",
        "print(paragraph)\n",
        "print(\"\\nDetected MWEs:\")\n",
        "for m in detected:\n",
        "    print(\"-\", m)\n"
      ],
      "metadata": {
        "id": "LYNlDnMVpIDF",
        "outputId": "3d68090d-e2ba-473d-ea9a-5b9c8b47a7ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paragraph:\n",
            "John lives in New York City. By and large, he enjoys it there, but sometimes he feels like he might kick the bucket from stress.\n",
            "\n",
            "Detected MWEs:\n",
            "- New York City\n",
            "- kick the bucket\n",
            "- by and large\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "Naive_space_tokenization.ipynb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}